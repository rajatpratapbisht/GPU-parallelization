{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761559e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Core ML/DL libs\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# %pip install tensorflow\n",
    "# %pip install scikit-learn\n",
    "\n",
    "# # Data and file handeling\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "\n",
    "# # dev tools\n",
    "# %pip install jupyter notebook\n",
    "\n",
    "# # visualization\n",
    "# %pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05787ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Device: cuda\n",
      "# Devices: 2\n"
     ]
    }
   ],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    num_devices = torch.cuda.device_count()\n",
    "else:\n",
    "    num_devices=torch.cpu.device_count()\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"# Devices: {num_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df697d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_matrix_multiply(device, size=1024):\n",
    "    print(f\"\\nRunning on: {device}\")\n",
    "\n",
    "    # Create random matrices on the GPU\n",
    "    A = torch.randn(size, size, device=device)\n",
    "    B = torch.randn(size, size, device=device)\n",
    "\n",
    "    torch.cuda.synchronize()  # Wait for GPU to be ready\n",
    "    start = time.time()\n",
    "\n",
    "    C = torch.matmul(A, B)\n",
    "\n",
    "    torch.cuda.synchronize()  # Wait for the op to finish\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication completed on {device} in {end - start:.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5a8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################\n",
      "Checking number of available GPUs...\n",
      "#####################################\n",
      "\n",
      "Running on: cuda:0\n",
      "Matrix multiplication completed on cuda:0 in 0.0007 seconds.\n",
      "\n",
      "Running on: cuda:1\n",
      "Matrix multiplication completed on cuda:1 in 0.0002 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"#####################################\")\n",
    "print(\"Checking number of available GPUs...\")\n",
    "print(\"#####################################\")\n",
    "\n",
    "if device.type != \"cuda\":\n",
    "    print(\"CUDA not available. Exiting.\")\n",
    "    exit()\n",
    "    \n",
    "for i in range(num_devices):\n",
    "    device = torch.device(f\"cuda:{i}\")\n",
    "    gpu_matrix_multiply(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
